# -*- coding: utf-8 -*-
"""Proyek Pertama - ML Terapan

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UuE_yEUbFYQZoFLYLF9kUreRT1cAapCv

Import Library yang digunakan
"""

import numpy as np
import pandas as pd
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn import preprocessing

"""Load data dan Melihat list column data"""

df = pd.read_csv('bike_sharing_dataset.csv')
df.head()

"""visualisasikan data untuk melihat pola nya."""

dates = df['date'].values
viz_data  = df['total_cust'].values
 
 
plt.figure(figsize=(15,5))
plt.plot(dates, viz_data)
plt.title('Total Customer',
          fontsize=8);

"""Visualisasi Temp Observe untuk melihat sekilah pola data"""

dates = df['date'].values
viz_data  = df['temp_observ'].values
 
 
plt.figure(figsize=(15,5))
plt.plot(dates, viz_data)
plt.title('Temp Observe',
          fontsize=20);

"""Cleansing Data dengan mengubah Nilai NAN dengan 0 (sesuai dengan fiturnya), lalu melihat sekilas datanya kembali"""

df = df.fillna(0)
df.head()

"""drop kolom yang tidak dipakai ( pemilihan kolom paling berpengaruh )"""

df = df.drop(columns=['wind', 'casual', 'registered', 'temp_avg', 'temp_min', 'temp_max', 'wt_fog', 'wt_heavy_fog', 'wt_thunder', 'wt_sleet', 'wt_hail', 'wt_glaze', 'wt_haze', 'wt_drift_snow', 'wt_high_wind', 'wt_mist', 'wt_drizzle', 'wt_rain', 'wt_freeze_rain', 'wt_snow', 'wt_ground_fog', 'wt_ice_fog', 'wt_freeze_drizzle', 'wt_unknown', 'holiday'])

"""Normalisasi Data Dengan Min Max Scaler"""

# Min Max Scaler

df[['temp_observ', 'total_cust']] = preprocessing.MinMaxScaler().fit_transform(df[['temp_observ', 'total_cust']].values)

"""Menghilangkan outlier pada target data, dan visualisasi ulang data untuk melihat sekilas data"""

q = df["total_cust"].quantile(0.99)
df = df[df["total_cust"] < q]

dates = df['date'].values
viz_data  = df['total_cust'].values
 
 
plt.figure(figsize=(15,5))
plt.plot(dates, viz_data)
plt.title('Total Customer',
          fontsize=20);

"""Set Target Data untuk dilakukan prediksi"""

temp = df['total_cust']

"""Split Data train dan data test"""

data_latih, data_test = train_test_split(temp, test_size=0.2, shuffle=False)

"""Lihat estimasi threshold mae untuk evaluasi model"""

threshold_mae = (df['total_cust'].max() - df['total_cust'].min()) * 20/100
threshold_mae

"""Untuk mengambil kumpulan data dan mempartisinya sesuai dengan parameter yang dimasukan"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

"""Membagi dataset dan membuat model untuk sekuensial yang terdiri dari beberapa lapisan. Dan digunakan algoritma LSTM."""

train_set = windowed_dataset(data_latih, window_size=20, batch_size=600, shuffle_buffer=1000)
test_set = windowed_dataset(data_test, window_size=20, batch_size=600, shuffle_buffer=1000)
model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(128, return_sequences=True),
  tf.keras.layers.Dropout(0.6),
  tf.keras.layers.Dense(32, activation="relu"),
  tf.keras.layers.Dense(1, activation="relu"),
])

"""Fungsi Callback untuk menghentikan pembelajaran ketika pembelajaran model sesuai dengan target"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    threshold_mae = (df['total_cust'].max() - df['total_cust'].min()) * 20/100
    if(logs.get('val_mae')<threshold_mae):
      print("\nMAE < 20%")
      self.model.stop_training = True
callbacks = myCallback()

"""Eksekusi model"""

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-03, momentum=0.98)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
history = model.fit(train_set,epochs=30, validation_data=(test_set), callbacks=[callbacks])

"""Visualisasi MAE model"""

import matplotlib.pyplot as plt
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('MAE Model')
plt.ylabel('mae')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Visualisasi Loss Model"""

import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()